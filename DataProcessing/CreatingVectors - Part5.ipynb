{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import json\n",
    "import twint\n",
    "import networkx as nx\n",
    "from networkx.readwrite import json_graph\n",
    "import requests\n",
    "import os.path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_graph(filename):\n",
    "    with open(filename) as f:\n",
    "        js_graph = json.load(f)\n",
    "    return json_graph.node_link_graph(js_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# twint does not provide the support to get the usernames of the retweeters yet. Hence the function\n",
    "def get_retweeters_list(username, tweet_id):\n",
    "    # get the data of retweets\n",
    "    r = requests.get('https://twitter.com/i/activity/retweeted_popup?id='+tweet_id)\n",
    "    # use the grep in order to getch the retweeters\n",
    "    text = r.text\n",
    "    x = re.findall('div class=\\\\\\\\\"account  js-actionable-user js-profile-popup-actionable \\\\\\\\\" data-screen-name=\\\\\\\\\"(.+?)\\\\\\\\\" data-user-id=\\\\\\\\\"', text)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tweets that have been retweeted\n",
    "def get_tweet_id(username):\n",
    "    # open the tweets file of the user\n",
    "    retweeted_tweets = []\n",
    "    ids_list = []\n",
    "    try:\n",
    "        with open('StronglyConnectedUsers/'+username+'.csv') as csvfile:\n",
    "            readCSV = csv.reader(csvfile, delimiter=',')\n",
    "            for row in readCSV:\n",
    "                if row[3] != '0' and row[1] != 'id' and row[2] == username :\n",
    "                    retweeted_tweets.append(row[1])\n",
    "    except:\n",
    "        pass\n",
    "    # return a list of tweet ID's\n",
    "    return(retweeted_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>First_Topic</th>\n",
       "      <th>Second_Topic</th>\n",
       "      <th>Third_Topic</th>\n",
       "      <th>Document_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>clean_deborah_fraser_.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>clean_naolifant.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>clean_hotbwoyp.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>clean_Tnngcobo.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>clean_mshalisto.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Document_No  First_Topic  Second_Topic  Third_Topic  \\\n",
       "0           0            0          3.0           1.0          5.0   \n",
       "1           1            1          7.0           5.0          4.0   \n",
       "2           2            2          7.0           5.0          2.0   \n",
       "3           3            3          4.0           3.0          5.0   \n",
       "4           4            4          1.0           4.0          5.0   \n",
       "\n",
       "                 Document_ID  \n",
       "0  clean_deborah_fraser_.csv  \n",
       "1        clean_naolifant.csv  \n",
       "2         clean_hotbwoyp.csv  \n",
       "3         clean_Tnngcobo.csv  \n",
       "4        clean_mshalisto.csv  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/savanpatel/Desktop/sfsu/research/spamDetection/SDUTDPRev3/DataProcessing/DominantTopics.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0\n"
     ]
    }
   ],
   "source": [
    "max_topics = data['First_Topic'].max() + 1\n",
    "print(max_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interested_topic(username):\n",
    "    row = data[data['Document_ID'].str.contains(username)]\n",
    "    return row['First_Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: First_Topic, dtype: float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_topic('RedneckTWD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "json_graph.json\n",
      "{'json_graph.json': ['WhiteMediafrica', 'Uzalo_SABC1', 'oscar_Udeddie', 'Beevatar', 'DumiB_Nabalalel', 'khanyacomms', 'themusicimbizo', 'nelisiwe_sibiya', 'OmegaXDreams', 'NeoNtlatleng', 'Cafeskyzer11', 'SowetoTVchannel', 'ProtectionIngwe', 'soozandbnnyt', 'sa_artists', 'nam_radio', 'duduWagaG', 'Simps_majola', 'PASTABDXLL', 'durbanjozinites', 'ZakweSA', 'Alyscia_C', 'LalombaMusic', 'mlutheartist', 'SADJAwards', 'Ladylatta', 'LwaziGB_SA', 'jet_dynamics', 'MillyMashile', 'TheMusicDA', 'MusicBoxEntSA', 'RealDjTerance', 'MuNgcolosi', 'MajorArtOffice', 'Thokozani_Hlong', 'blose2sizwe', 'TongaatBeach', 'IamParadise_Sa', 'Tebogo_Louw', 'sanele_mkhizeh', 'JarredLove13', 'DiseboMusic', 'BoogieHarrySA', 'NocxyMabika', 'BishopthandaM', 'Thabzero_NUZ', 'hotbwoyp', 'Sjerere_dj', 'sosha745', 'nathi_mankayi', 'Zuka_DC', 'MeetKingKoolie', 'KaMavusoSA', 'Iambusin_sa', 'IAMYNGKING', 'MlixxFR', 'Tnngcobo', 'Oz_Lindokuhle', 'siphelele_fuze', 'Karabo_Mokgoko', 'PoetMastermind', 'seanhchoe', 'DJ_Pearl_Bahle', 'NhlanhlaNhlapo', 'AndileNgidi7', 'Bongani76Mavuso', 'djsbu', 'ZarciaZA', 'ThizaKhumalo', 'HillbrowRadio', 'Eassy__', 'MashabaWinnie', 'deejayprincesa', 'TheLeg3ndary', 'Cuebur', 'Dancegoddess1', 'khanyaBHAR', 'phindilephewa', 'sphongolishSA', 'DjSpin745', 'HomyBeezSA', 'Moni_R', 'Chymamusique', 'PzetSA', 'Mapasexy', 'EarlCraig06', 'peterndoro', 'ErnieSmithzn', 'workwthecoach', 'MrG_RSA', 'SirFestive', 'abaphathi', 'DJSQENGQE', 'UlrichJvV', 'xoliebhengu', 'JodyMasaEyez', 'YungFess', 'Nomigumede', 'mshalisto', 'malusimbokazi', 'ngidizanefa', 'Tha_DBN', 'ezasekhaya_arts', 'DeeJayHustle_MP', 'ZeegeeSa', 'dog_shinzo', 'ZuluBoyFriend', 'chynamandj', 'IamMzilikazi', 'Dj_Bongz', 'zanelemthethw17', 'LungiNaidoo', 'deborah_fraser_', 'naolifant', 'mapulemchunu', 'fananojobe1', 'ayandamsweli46', 'Blozey', 'Cne_Passion', 'ladydwabantu', 'MthunzigoodXulu', 'Diskiqueen_', 'djzeal4life', 'DjNdringos1', 'kholekamusic', 'moja_pooh', 'ThulaniGa', 'AmandaSoGood', 'MduNcalane', 'Uvukilegospel', 'NdoniYoMoya', 'BuhleofGospel', 'AndileKaMajola', 'LuciaMthiyane', 'Yfm', 'sparksbantwana', 'Bhekamchunu', 'MthoshDlamini', 'JacintaNgobese', 'PhumlaniNkwanya', 'SabcCrownAwards', 'TeddyXaba', 'mkokstad_dumi', 'LeehRadioDj', 'LuckySefatsa', 'dj_cndo', 'iamCollenZondo', 'SandyBMegastar', 'djmngadi', 'mondlimzizi', 'Uguyouthradio', '1Mevana', 'SiinaNina', 'CHAVISTO_FRANCE', 'MsajeroRSA', 'DJVUMAR', 'naimakaysa', 'AlexMthiyane', 'DjBrightSA', 'simisojaca', 'Nqubekondlela']}\n",
      "161\n"
     ]
    }
   ],
   "source": [
    "sub_graphs = ['json_graph.json']\n",
    "print(len(sub_graphs))\n",
    "complete_list_of_users = []\n",
    "node_dict = {}\n",
    "for item1 in sub_graphs:\n",
    "    print(item1)\n",
    "    # for each subgraph, get all the nodes and extract their top tweets\n",
    "    G = nx.Graph()\n",
    "    G = read_json_graph(item1)\n",
    "    list_of_user = list(G.nodes)\n",
    "    node_dict[item1] = list_of_user\n",
    "    for item in list_of_user:\n",
    "        complete_list_of_users.append(item)\n",
    "print(node_dict)\n",
    "print(len(complete_list_of_users))\n",
    "with open('complete_list_of_users.txt', 'w') as f:  \n",
    "    for user in complete_list_of_users:\n",
    "        f.write('%s\\n' % user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAfter saving the users to acomplete_list_of_users.txt, run the tweet collection code from Pycharm.\\nDue to the underlying issues of jupyter, data collection code breaks while executing it here.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "After saving the users to acomplete_list_of_users.txt, run the tweet collection code from Pycharm.\n",
    "Due to the underlying issues of jupyter, data collection code breaks while executing it here.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the old file and create a new blank one\n",
    "if os.path.isfile(\"vector.csv\"):\n",
    "    print(\"file exists\")\n",
    "    os.remove(\"vector.csv\")\n",
    "open(\"vector.csv\", 'a').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vector.csv', 'r+', newline='') as csvfile :\n",
    "    vector = csv.writer(csvfile, delimiter=',')\n",
    "    heading = list(range(1, int(max_topics)+1))\n",
    "    vector.writerow(['tweet_id']+heading)\n",
    "    buckets = [0] * int(max_topics)\n",
    "    for user in complete_list_of_users:\n",
    "        # get list of tweet_id of retweeted tweets\n",
    "        ids_of_retweeted_tweets = get_tweet_id(user)\n",
    "        for id_tweet in ids_of_retweeted_tweets:\n",
    "            # add a row to the csv file with the tweet_id\n",
    "            row = [id_tweet]\n",
    "            row.extend((buckets))\n",
    "            # get the usernames of the retweeters\n",
    "            retweeters = []\n",
    "            retweeters = get_retweeters_list(user, id_tweet)\n",
    "            # add tweet's oroginal poster to the list of retweeters to the vector\n",
    "            retweeters.append(user)\n",
    "            #print(id_tweet)\n",
    "            #print(retweeters)\n",
    "            # for each retweeter check if the retweeter is in the complete list of users\n",
    "            for retweeter in retweeters:\n",
    "                if retweeter in complete_list_of_users:\n",
    "                    # if the retweeter exists in the complete list of users check which topic he/she is interested in\n",
    "                    try:\n",
    "                        topic = int(interested_topic(retweeter)) + 1\n",
    "                    except TypeError:\n",
    "                        pass\n",
    "                    #print(retweeter+\"is interested in \"+str(topic))\n",
    "                    # get the existing count for that topic\n",
    "                    count = row[topic]\n",
    "                    count = count + 1\n",
    "                    row[topic] = count\n",
    "            vector.writerow(row)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nExtracting tweets with more than 1 value in the vector or having a single value of more than 1\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Extracting tweets with more than 1 value in the vector or having a single value of more than 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the old file and create a new blank one\n",
    "if os.path.isfile(\"reducedVector.csv\"):\n",
    "    print(\"file exists\")\n",
    "    os.remove(\"reducedVector.csv\")\n",
    "open(\"reducedVector.csv\", 'a').close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalVectors = 0\n",
    "oneNonZero = 0\n",
    "OneNonZero = 0\n",
    "TwoNonZero = 0\n",
    "ThreeNonZero = 0\n",
    "FourNonZero = 0\n",
    "moreThanFourNonZero = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vector.csv', 'r', newline='') as csvfile :\n",
    "    vectors = csv.reader(csvfile, delimiter=',')\n",
    "    for vector in vectors:\n",
    "        if vector[0] == 'tweet_id':\n",
    "            continue\n",
    "        totalVectors = totalVectors + 1\n",
    "        nonZeroValues = 0\n",
    "        for item in range(1,len(vector)):\n",
    "            if int(vector[item]) > 0:\n",
    "                nonZeroValues = nonZeroValues + 1\n",
    "        if nonZeroValues > 1:\n",
    "            with open('reducedVector.csv', 'a', newline='') as reducedFile:\n",
    "                vector2 = csv.writer(reducedFile, delimiter=',')\n",
    "                vector2.writerow(vector)\n",
    "        if nonZeroValues >= 3:\n",
    "            with open('ThreeNonZeroVector.csv', 'a', newline='') as reducedFile:\n",
    "                vector2 = csv.writer(reducedFile, delimiter=',')\n",
    "                vector2.writerow(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
